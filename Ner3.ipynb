{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to train_data.csv\n",
      "Saved processed data to eval_data.csv\n",
      "Saved processed data to test_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ฟังก์ชันสำหรับอ่านไฟล์จากโฟลเดอร์\n",
    "def read_data_from_folder(folder_path):\n",
    "    data = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                for line in file:\n",
    "                    line = line.strip()\n",
    "                    if line:  # ข้ามแถวว่าง\n",
    "                        parts = line.split(\"\\t\")\n",
    "                        if len(parts) == 4:  # ถ้ามี 4 คอลัมน์\n",
    "                            data.append(parts)\n",
    "                        elif len(parts) == 3:  # ถ้ามี 3 คอลัมน์ เติมค่า default สำหรับ `tag`\n",
    "                            parts.insert(2, \"O\")  # ใส่ค่า \"O\" ที่ตำแหน่ง index 2\n",
    "                            data.append(parts)\n",
    "                        else:\n",
    "                            print(f\"Invalid line in {file_name}: {line}\")\n",
    "    return data\n",
    "\n",
    "# ฟังก์ชันสำหรับรวบรวมและบันทึกข้อมูล\n",
    "def process_and_save_data(input_folder, output_file):\n",
    "    data = read_data_from_folder(input_folder)\n",
    "    df = pd.DataFrame(data, columns=[\"word\", \"pos\", \"tag\", \"class\"])\n",
    "    df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Saved processed data to {output_file}\")\n",
    "\n",
    "# โฟลเดอร์ข้อมูล\n",
    "train_folder = \"train\"\n",
    "test_folder = \"test\"\n",
    "eval_folder = \"eval\"\n",
    "\n",
    "# เซฟข้อมูลเป็นไฟล์ CSV\n",
    "process_and_save_data(train_folder, \"train_data.csv\")\n",
    "process_and_save_data(eval_folder, \"eval_data.csv\")\n",
    "process_and_save_data(test_folder, \"test_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>สภาสังคมสงเคราะห์แห่งประเทศ</td>\n",
       "      <td>NN</td>\n",
       "      <td>B_ORG</td>\n",
       "      <td>B_CLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ไทย</td>\n",
       "      <td>NN</td>\n",
       "      <td>E_ORG</td>\n",
       "      <td>I_CLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>จี้</td>\n",
       "      <td>VV</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ศาล</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ไฟเขียว</td>\n",
       "      <td>VV</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804216</th>\n",
       "      <td>ระหว่าง</td>\n",
       "      <td>PS</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804217</th>\n",
       "      <td>เรียน</td>\n",
       "      <td>VV</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804218</th>\n",
       "      <td>กับ</td>\n",
       "      <td>PS</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804219</th>\n",
       "      <td>งาน</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804220</th>\n",
       "      <td>\"</td>\n",
       "      <td>PU</td>\n",
       "      <td>O</td>\n",
       "      <td>E_CLS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2804221 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                word pos    tag  class\n",
       "0        สภาสังคมสงเคราะห์แห่งประเทศ  NN  B_ORG  B_CLS\n",
       "1                                ไทย  NN  E_ORG  I_CLS\n",
       "2                                จี้  VV      O  I_CLS\n",
       "3                                ศาล  NN      O  I_CLS\n",
       "4                            ไฟเขียว  VV      O  I_CLS\n",
       "...                              ...  ..    ...    ...\n",
       "2804216                      ระหว่าง  PS      O  I_CLS\n",
       "2804217                        เรียน  VV      O  I_CLS\n",
       "2804218                          กับ  PS      O  I_CLS\n",
       "2804219                          งาน  NN      O  I_CLS\n",
       "2804220                            \"  PU      O  E_CLS\n",
       "\n",
       "[2804221 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"train_data.csv\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tags: 32\n",
      "\n",
      "First few tags:\n",
      "     tag  class\n",
      "0      O      0\n",
      "1  B_ORG      1\n",
      "2  B_PER      2\n",
      "3  B_LOC      3\n",
      "4  B_MEA      4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read tag list\n",
    "tag_df = pd.read_csv('tag_list.csv')\n",
    "print(\"Number of unique tags:\", len(tag_df))\n",
    "print(\"\\nFirst few tags:\")\n",
    "print(tag_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag to Index mapping:\n",
      "O: 0\n",
      "B_ORG: 1\n",
      "B_PER: 2\n",
      "B_LOC: 3\n",
      "B_MEA: 4\n",
      "I_DTM: 5\n",
      "I_ORG: 6\n",
      "E_ORG: 7\n",
      "I_PER: 8\n",
      "B_TTL: 9\n",
      "E_PER: 10\n",
      "B_DES: 11\n",
      "E_LOC: 12\n",
      "B_DTM: 13\n",
      "B_NUM: 14\n",
      "I_MEA: 15\n",
      "E_DTM: 16\n",
      "E_MEA: 17\n",
      "I_LOC: 18\n",
      "I_DES: 19\n",
      "E_DES: 20\n",
      "I_NUM: 21\n",
      "E_NUM: 22\n",
      "B_TRM: 23\n",
      "B_BRN: 24\n",
      "I_TRM: 25\n",
      "E_TRM: 26\n",
      "I_TTL: 27\n",
      "I_BRN: 28\n",
      "E_BRN: 29\n",
      "E_TTL: 30\n",
      "B_NAME: 31\n",
      "\n",
      "Index to Tag mapping:\n",
      "0: O\n",
      "1: B_ORG\n",
      "2: B_PER\n",
      "3: B_LOC\n",
      "4: B_MEA\n",
      "5: I_DTM\n",
      "6: I_ORG\n",
      "7: E_ORG\n",
      "8: I_PER\n",
      "9: B_TTL\n",
      "10: E_PER\n",
      "11: B_DES\n",
      "12: E_LOC\n",
      "13: B_DTM\n",
      "14: B_NUM\n",
      "15: I_MEA\n",
      "16: E_DTM\n",
      "17: E_MEA\n",
      "18: I_LOC\n",
      "19: I_DES\n",
      "20: E_DES\n",
      "21: I_NUM\n",
      "22: E_NUM\n",
      "23: B_TRM\n",
      "24: B_BRN\n",
      "25: I_TRM\n",
      "26: E_TRM\n",
      "27: I_TTL\n",
      "28: I_BRN\n",
      "29: E_BRN\n",
      "30: E_TTL\n",
      "31: B_NAME\n",
      "\n",
      "Example usage:\n",
      "Convert 'B_ORG' to index: 1\n",
      "Convert index 1 back to tag: B_ORG\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# อ่านไฟล์ tag_list.csv\n",
    "df_tags = pd.read_csv('tag_list.csv')\n",
    "\n",
    "# สร้าง mapping dictionaries ตาม class ที่มีอยู่แล้วใน CSV\n",
    "tag2idx = dict(zip(df_tags['tag'], df_tags['class']))\n",
    "idx2tag = dict(zip(df_tags['class'], df_tags['tag']))\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(\"Tag to Index mapping:\")\n",
    "for tag, idx in tag2idx.items():\n",
    "    print(f\"{tag}: {idx}\")\n",
    "\n",
    "print(\"\\nIndex to Tag mapping:\")\n",
    "for idx, tag in idx2tag.items():\n",
    "    print(f\"{idx}: {tag}\")\n",
    "\n",
    "# เก็บ mapping ไว้ใช้ต่อ\n",
    "np.save('tag2idx.npy', tag2idx) \n",
    "np.save('idx2tag.npy', idx2tag)\n",
    "\n",
    "# ตัวอย่างการใช้งาน\n",
    "print(\"\\nExample usage:\")\n",
    "print(f\"Convert 'B_ORG' to index: {tag2idx['B_ORG']}\")\n",
    "print(f\"Convert index 1 back to tag: {idx2tag[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from training data:\n",
      "  pos    tag  numeric_tag\n",
      "0  NN  B_ORG          1.0\n",
      "1  NN  E_ORG          7.0\n",
      "2  VV      O          0.0\n",
      "3  NN      O          0.0\n",
      "4  VV      O          0.0\n",
      "\n",
      "Verify conversion back to tags:\n",
      "Numeric tag: 1.0\n",
      "Original tag: B_ORG\n",
      "\n",
      "Dataset statistics:\n",
      "Train samples: 2804221\n",
      "Test samples: 213091\n",
      "Eval samples: 248470\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. โหลด mapping ที่สร้างไว้\n",
    "tag2idx = np.load('tag2idx.npy', allow_pickle=True).item()\n",
    "idx2tag = np.load('idx2tag.npy', allow_pickle=True).item()\n",
    "\n",
    "# 2. ฟังก์ชันสำหรับอ่านและแปลงข้อมูล\n",
    "def process_data_file(file_path):\n",
    "    # อ่านข้อมูลจาก CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # แปลง tags เป็น numeric โดยใช้ tag2idx mapping\n",
    "    df['numeric_tag'] = df['tag'].map(tag2idx)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 3. อ่านและแปลงข้อมูลทั้ง 3 ชุด\n",
    "train_df = process_data_file('train_data.csv')\n",
    "test_df = process_data_file('test_data.csv')\n",
    "eval_df = process_data_file('eval_data.csv')\n",
    "\n",
    "# 4. แสดงตัวอย่างผลลัพธ์\n",
    "print(\"Sample from training data:\")\n",
    "print(train_df[['pos', 'tag', 'numeric_tag']].head())\n",
    "\n",
    "# 5. ตรวจสอบการแปลงกลับ\n",
    "print(\"\\nVerify conversion back to tags:\")\n",
    "sample_numeric = train_df['numeric_tag'].iloc[0]\n",
    "print(f\"Numeric tag: {sample_numeric}\")\n",
    "print(f\"Original tag: {idx2tag[sample_numeric]}\")\n",
    "\n",
    "# 6. บันทึกข้อมูลที่แปลงแล้ว\n",
    "train_df.to_csv('processed_train.csv', index=False)\n",
    "test_df.to_csv('processed_test.csv', index=False)\n",
    "eval_df.to_csv('processed_eval.csv', index=False)\n",
    "\n",
    "# 7. แสดงสถิติ\n",
    "print(\"\\nDataset statistics:\")\n",
    "print(f\"Train samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"Eval samples: {len(eval_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>class</th>\n",
       "      <th>numeric_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>สภาสังคมสงเคราะห์แห่งประเทศ</td>\n",
       "      <td>NN</td>\n",
       "      <td>B_ORG</td>\n",
       "      <td>B_CLS</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ไทย</td>\n",
       "      <td>NN</td>\n",
       "      <td>E_ORG</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>จี้</td>\n",
       "      <td>VV</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ศาล</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ไฟเขียว</td>\n",
       "      <td>VV</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804216</th>\n",
       "      <td>ระหว่าง</td>\n",
       "      <td>PS</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804217</th>\n",
       "      <td>เรียน</td>\n",
       "      <td>VV</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804218</th>\n",
       "      <td>กับ</td>\n",
       "      <td>PS</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804219</th>\n",
       "      <td>งาน</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804220</th>\n",
       "      <td>\"</td>\n",
       "      <td>PU</td>\n",
       "      <td>O</td>\n",
       "      <td>E_CLS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2804221 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                word pos    tag  class  numeric_tag\n",
       "0        สภาสังคมสงเคราะห์แห่งประเทศ  NN  B_ORG  B_CLS          1.0\n",
       "1                                ไทย  NN  E_ORG  I_CLS          7.0\n",
       "2                                จี้  VV      O  I_CLS          0.0\n",
       "3                                ศาล  NN      O  I_CLS          0.0\n",
       "4                            ไฟเขียว  VV      O  I_CLS          0.0\n",
       "...                              ...  ..    ...    ...          ...\n",
       "2804216                      ระหว่าง  PS      O  I_CLS          0.0\n",
       "2804217                        เรียน  VV      O  I_CLS          0.0\n",
       "2804218                          กับ  PS      O  I_CLS          0.0\n",
       "2804219                          งาน  NN      O  I_CLS          0.0\n",
       "2804220                            \"  PU      O  E_CLS          0.0\n",
       "\n",
       "[2804221 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# โหลดข้อมูลจากไฟล์ CSV\n",
    "input_csv = \"train_data.csv\"  # ชื่อไฟล์ CSV ของคุณ\n",
    "output_txt = \"train_ner.txt\"  # ชื่อไฟล์ที่จะแปลง\n",
    "\n",
    "# อ่านข้อมูล CSV\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# เลือกเฉพาะคอลัมน์ที่ต้องการ (word, pos, tag)\n",
    "columns_to_use = [\"word\", \"pos\", \"tag\"]\n",
    "df = df[columns_to_use]\n",
    "\n",
    "# ตรวจสอบว่าข้อมูลเรียงตามลำดับประโยคหรือไม่ (ถ้ามีข้อมูลแบ่งประโยค)\n",
    "# ถ้าไม่มีข้อมูลแบ่งประโยค ให้ใช้ logic แทรกบรรทัดว่างเองตามต้องการ\n",
    "\n",
    "# เขียนข้อมูลให้อยู่ในรูปแบบ NER\n",
    "with open(output_txt, \"w\", encoding=\"utf-8\") as file:\n",
    "    for _, row in df.iterrows():\n",
    "        if row[\"word\"] == \"\":\n",
    "            file.write(\"\\n\")  # บรรทัดว่างสำหรับแยกประโยค\n",
    "        else:\n",
    "            file.write(f\"{row['word']} {row['pos']} {row['tag']}\\n\")\n",
    "\n",
    "print(f\"แปลงข้อมูลเสร็จสิ้นและบันทึกไว้ใน {output_txt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. Shapes:\n",
      "Train: (2804221, 5)\n",
      "Test: (213091, 5)\n",
      "Eval: (248470, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\potij\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# 1. Import required libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 2. Load data\n",
    "train_df = pd.read_csv('processed_train.csv')\n",
    "test_df = pd.read_csv('processed_test.csv')\n",
    "eval_df = pd.read_csv('processed_eval.csv')\n",
    "\n",
    "print(\"Data loaded. Shapes:\")\n",
    "print(f\"Train: {train_df.shape}\")\n",
    "print(f\"Test: {test_df.shape}\")\n",
    "print(f\"Eval: {eval_df.shape}\")\n",
    "\n",
    "# 3. Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>class</th>\n",
       "      <th>numeric_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>สภาสังคมสงเคราะห์แห่งประเทศ</td>\n",
       "      <td>NN</td>\n",
       "      <td>B_ORG</td>\n",
       "      <td>B_CLS</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ไทย</td>\n",
       "      <td>NN</td>\n",
       "      <td>E_ORG</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>จี้</td>\n",
       "      <td>VV</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ศาล</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ไฟเขียว</td>\n",
       "      <td>VV</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804216</th>\n",
       "      <td>ระหว่าง</td>\n",
       "      <td>PS</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804217</th>\n",
       "      <td>เรียน</td>\n",
       "      <td>VV</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804218</th>\n",
       "      <td>กับ</td>\n",
       "      <td>PS</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804219</th>\n",
       "      <td>งาน</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804220</th>\n",
       "      <td>\"</td>\n",
       "      <td>PU</td>\n",
       "      <td>O</td>\n",
       "      <td>E_CLS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2804221 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                word pos    tag  class  numeric_tag\n",
       "0        สภาสังคมสงเคราะห์แห่งประเทศ  NN  B_ORG  B_CLS          1.0\n",
       "1                                ไทย  NN  E_ORG  I_CLS          7.0\n",
       "2                                จี้  VV      O  I_CLS          0.0\n",
       "3                                ศาล  NN      O  I_CLS          0.0\n",
       "4                            ไฟเขียว  VV      O  I_CLS          0.0\n",
       "...                              ...  ..    ...    ...          ...\n",
       "2804216                      ระหว่าง  PS      O  I_CLS          0.0\n",
       "2804217                        เรียน  VV      O  I_CLS          0.0\n",
       "2804218                          กับ  PS      O  I_CLS          0.0\n",
       "2804219                          งาน  NN      O  I_CLS          0.0\n",
       "2804220                            \"  PU      O  E_CLS          0.0\n",
       "\n",
       "[2804221 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create Dataset class\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=128):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Group by sentence\n",
    "        self.sentences = []\n",
    "        self.labels = []\n",
    "        current_sent = []\n",
    "        current_labels = []\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            if row['word'] in ['.', '\"']:  # End of sentence markers\n",
    "                if current_sent:\n",
    "                    self.sentences.append(current_sent)\n",
    "                    self.labels.append(current_labels)\n",
    "                    current_sent = []\n",
    "                    current_labels = []\n",
    "            else:\n",
    "                current_sent.append(row['word'])\n",
    "                current_labels.append(int(row['numeric_tag']))\n",
    "        \n",
    "        # Encode all sentences\n",
    "        self.encodings = tokenizer(\n",
    "            self.sentences,\n",
    "            is_split_into_words=True,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Align labels\n",
    "        self.aligned_labels = self._align_labels()\n",
    "    \n",
    "    def _align_labels(self):\n",
    "        aligned_labels = []\n",
    "        for i, label in enumerate(self.labels):\n",
    "            word_ids = self.encodings.word_ids(i)\n",
    "            previous_word_idx = None\n",
    "            label_ids = []\n",
    "            \n",
    "            for word_idx in word_ids:\n",
    "                if word_idx is None:\n",
    "                    label_ids.append(-100)\n",
    "                elif word_idx != previous_word_idx:\n",
    "                    label_ids.append(label[word_idx])\n",
    "                else:\n",
    "                    label_ids.append(-100)\n",
    "                previous_word_idx = word_idx\n",
    "                \n",
    "            aligned_labels.append(label_ids)\n",
    "        return aligned_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': torch.tensor(self.aligned_labels[idx])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking NaN values:\n",
      "word              0\n",
      "pos               0\n",
      "tag               0\n",
      "class             0\n",
      "numeric_tag    1810\n",
      "dtype: int64\n",
      "\n",
      "Data types after conversion:\n",
      "word           object\n",
      "pos            object\n",
      "tag            object\n",
      "class          object\n",
      "numeric_tag     int32\n",
      "dtype: object\n",
      "\n",
      "Verifying NaN values after cleaning:\n",
      "word           0\n",
      "pos            0\n",
      "tag            0\n",
      "class          0\n",
      "numeric_tag    0\n",
      "dtype: int64\n",
      "\n",
      "Datasets created successfully!\n",
      "Train dataset size: 19941\n"
     ]
    }
   ],
   "source": [
    "# 1. Check NaN values\n",
    "print(\"Checking NaN values:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "# 2. Clean data by dropping NaN or filling them\n",
    "train_df = train_df.fillna(0)  # หรือใช้ dropna() ถ้าต้องการลบแถวที่มี NaN\n",
    "test_df = test_df.fillna(0)\n",
    "eval_df = eval_df.fillna(0)\n",
    "\n",
    "# 3. Convert float labels to integers\n",
    "train_df['numeric_tag'] = train_df['numeric_tag'].astype(int)\n",
    "test_df['numeric_tag'] = test_df['numeric_tag'].astype(int)\n",
    "eval_df['numeric_tag'] = eval_df['numeric_tag'].astype(int)\n",
    "\n",
    "print(\"\\nData types after conversion:\")\n",
    "print(train_df.dtypes)\n",
    "\n",
    "# 4. Verify no NaN values remain\n",
    "print(\"\\nVerifying NaN values after cleaning:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "# 5. Create datasets again\n",
    "train_dataset = NERDataset(train_df, tokenizer)\n",
    "test_dataset = NERDataset(test_df, tokenizer)\n",
    "eval_dataset = NERDataset(eval_df, tokenizer)\n",
    "\n",
    "print(\"\\nDatasets created successfully!\")\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying data:\n",
      "Batch input shape: torch.Size([16, 128])\n",
      "Batch label shape: torch.Size([16, 128])\n",
      "\n",
      "Data preparation completed and saved!\n"
     ]
    }
   ],
   "source": [
    "# 6. Create DataLoaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=batch_size)\n",
    "\n",
    "# 7. Verify data\n",
    "print(\"\\nVerifying data:\")\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"Batch input shape: {sample_batch['input_ids'].shape}\")\n",
    "print(f\"Batch label shape: {sample_batch['labels'].shape}\")\n",
    "\n",
    "# 8. Save prepared data\n",
    "torch.save({\n",
    "    'train_dataset': train_dataset,\n",
    "    'test_dataset': test_dataset,\n",
    "    'eval_dataset': eval_dataset\n",
    "}, 'prepared_datasets.pt')\n",
    "\n",
    "print(\"\\nData preparation completed and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1f2001cd670>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1f1b3167380>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"test/test/\"  \n",
    "\n",
    "all_data = []\n",
    "all_sentences = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, file_name)  \n",
    "\n",
    "\n",
    "\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        s = []  \n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            for line in file:\n",
    "                i += 1\n",
    "                tokens = line.strip().split(\"\\t\")  \n",
    "                if len(tokens) == 3:\n",
    "                    word, pos, label = tokens\n",
    "                    all_data.append({\"word\": word, \"pos\": pos, \"label\": label})\n",
    "                    s.append(word)  \n",
    "        all_sentences.append(s) \n",
    "\n",
    "\n",
    "print(all_sentences[0][0:10]) \n",
    "\n",
    "\n",
    "print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
