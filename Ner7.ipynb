{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T06:51:58.060493Z",
     "iopub.status.busy": "2025-01-25T06:51:58.060045Z",
     "iopub.status.idle": "2025-01-25T06:52:25.981084Z",
     "shell.execute_reply": "2025-01-25T06:52:25.980159Z",
     "shell.execute_reply.started": "2025-01-25T06:51:58.060466Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to train_data.csv\n",
      "Saved processed data to eval_data.csv\n",
      "Saved processed data to test_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ฟังก์ชันสำหรับอ่านไฟล์จากโฟลเดอร์ตามลำดับ\n",
    "def read_data_from_folder(folder_path):\n",
    "    data = []\n",
    "    # เรียงลำดับชื่อไฟล์ตามลำดับตัวเลข\n",
    "    file_names = sorted(os.listdir(folder_path))\n",
    "    for file_name in file_names:\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                for line in file:\n",
    "                    line = line.strip()\n",
    "                    if line:  # ข้ามแถวว่าง\n",
    "                        parts = line.split(\"\\t\")\n",
    "                        if len(parts) == 4:  # ถ้ามี 4 คอลัมน์\n",
    "                            data.append(parts)\n",
    "                        elif len(parts) == 3:  # ถ้ามี 3 คอลัมน์ เติมค่า default สำหรับ `tag`\n",
    "                            parts.insert(2, \"O\")  # ใส่ค่า \"O\" ที่ตำแหน่ง index 2\n",
    "                            data.append(parts)\n",
    "                        else:\n",
    "                            print(f\"Invalid line in {file_name}: {line}\")\n",
    "    return data\n",
    "\n",
    "# ฟังก์ชันสำหรับรวบรวมและบันทึกข้อมูล\n",
    "def process_and_save_data(input_folder, output_file):\n",
    "    data = read_data_from_folder(input_folder)\n",
    "    df = pd.DataFrame(data, columns=[\"word\", \"pos\", \"tag\", \"class\"])\n",
    "    df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Saved processed data to {output_file}\")\n",
    "\n",
    "# โฟลเดอร์ข้อมูล (แก้ไขให้ตรงกับโครงสร้างใน Kaggle)\n",
    "train_folder = \"train\"\n",
    "test_folder = \"test\"\n",
    "eval_folder = \"eval\"\n",
    "\n",
    "# เซฟข้อมูลเป็นไฟล์ CSV\n",
    "process_and_save_data(train_folder, \"train_data.csv\")\n",
    "process_and_save_data(eval_folder, \"eval_data.csv\")\n",
    "process_and_save_data(test_folder, \"test_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = [\n",
    "    ('O', 0),\n",
    "    ('B_ORG', 1),  ('B_PER', 2),  ('B_LOC', 3),  ('B_MEA', 4),\n",
    "    ('I_DTM', 5),  ('I_ORG', 6),  ('E_ORG', 7),  ('I_PER', 8),\n",
    "    ('B_TTL', 9),  ('E_PER', 10), ('B_DES', 11), ('E_LOC', 12),\n",
    "    ('B_DTM', 13), ('B_NUM', 14), ('I_MEA', 15), ('E_DTM', 16),\n",
    "    ('E_MEA', 17), ('I_LOC', 18), ('I_DES', 19), ('E_DES', 20),\n",
    "    ('I_NUM', 21), ('E_NUM', 22), ('B_TRM', 23), ('B_BRN', 24),\n",
    "    ('I_TRM', 25), ('E_TRM', 26), ('I_TTL', 27), ('I_BRN', 28),\n",
    "    ('E_BRN', 29), ('E_TTL', 30), ('B_NAME', 31)\n",
    "]\n",
    "tag_to_id = dict(tag_list)\n",
    "id_to_tag = {v: k for k, v in tag_to_id.items()}\n",
    "\n",
    "def get_tag_id(tag):\n",
    "    # Map unknown tags to 0 (O)\n",
    "    return tag_to_id.get(tag, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B_ORG': 1,\n",
       " 'B_PER': 2,\n",
       " 'B_LOC': 3,\n",
       " 'B_MEA': 4,\n",
       " 'I_DTM': 5,\n",
       " 'I_ORG': 6,\n",
       " 'E_ORG': 7,\n",
       " 'I_PER': 8,\n",
       " 'B_TTL': 9,\n",
       " 'E_PER': 10,\n",
       " 'B_DES': 11,\n",
       " 'E_LOC': 12,\n",
       " 'B_DTM': 13,\n",
       " 'B_NUM': 14,\n",
       " 'I_MEA': 15,\n",
       " 'E_DTM': 16,\n",
       " 'E_MEA': 17,\n",
       " 'I_LOC': 18,\n",
       " 'I_DES': 19,\n",
       " 'E_DES': 20,\n",
       " 'I_NUM': 21,\n",
       " 'E_NUM': 22,\n",
       " 'B_TRM': 23,\n",
       " 'B_BRN': 24,\n",
       " 'I_TRM': 25,\n",
       " 'E_TRM': 26,\n",
       " 'I_TTL': 27,\n",
       " 'I_BRN': 28,\n",
       " 'E_BRN': 29,\n",
       " 'E_TTL': 30,\n",
       " 'B_NAME': 31}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T06:52:25.982813Z",
     "iopub.status.busy": "2025-01-25T06:52:25.982526Z",
     "iopub.status.idle": "2025-01-25T06:52:27.979665Z",
     "shell.execute_reply": "2025-01-25T06:52:27.978471Z",
     "shell.execute_reply.started": "2025-01-25T06:52:25.982789Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          word pos    tag  class\n",
      "0  สภาสังคมสงเคราะห์แห่งประเทศ  NN  B_ORG  B_CLS\n",
      "1                          ไทย  NN  E_ORG  I_CLS\n",
      "2                          จี้  VV      O  I_CLS\n",
      "3                          ศาล  NN      O  I_CLS\n",
      "4                      ไฟเขียว  VV      O  I_CLS\n",
      "    word pos    tag  class\n",
      "0   โฆษก  NN      O  B_CLS\n",
      "1   กอส.  NN  B_ORG  I_CLS\n",
      "2  ตำหนิ  VV      O  I_CLS\n",
      "3   แมนฯ  NN  B_ORG  I_CLS\n",
      "4      _  NN  I_ORG  I_CLS\n",
      "     word pos tag  class\n",
      "0     รัฐ  NN   O  B_CLS\n",
      "1  ถังแตก  VV   O  I_CLS\n",
      "2     วิก  NN   O  I_CLS\n",
      "3       _  NN   O  I_CLS\n",
      "4       7  NN   O  I_CLS\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# โหลดข้อมูล\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "eval_data = pd.read_csv('eval_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# ตรวจสอบตัวอย่างข้อมูล\n",
    "print(train_data.head())\n",
    "print(eval_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\n",
    "    'O',\n",
    "    'B_ORG', 'I_ORG', 'E_ORG',\n",
    "    'B_PER', 'I_PER', 'E_PER', \n",
    "    'B_LOC', 'I_LOC', 'E_LOC',\n",
    "    'B_MEA', 'I_MEA', 'E_MEA',\n",
    "    'B_DTM', 'I_DTM', 'E_DTM',\n",
    "    'B_NUM', 'I_NUM', 'E_NUM',\n",
    "    'B_TTL', 'I_TTL', 'E_TTL',\n",
    "    'B_DES', 'I_DES', 'E_DES',\n",
    "    'B_TRM', 'I_TRM', 'E_TRM',\n",
    "    'B_BRN', 'I_BRN', 'E_BRN',\n",
    "    'B_NAME'\n",
    "]\n",
    "\n",
    "tag_to_id = {tag: idx for idx, tag in enumerate(tags)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B_ORG': 1,\n",
       " 'I_ORG': 2,\n",
       " 'E_ORG': 3,\n",
       " 'B_PER': 4,\n",
       " 'I_PER': 5,\n",
       " 'E_PER': 6,\n",
       " 'B_LOC': 7,\n",
       " 'I_LOC': 8,\n",
       " 'E_LOC': 9,\n",
       " 'B_MEA': 10,\n",
       " 'I_MEA': 11,\n",
       " 'E_MEA': 12,\n",
       " 'B_DTM': 13,\n",
       " 'I_DTM': 14,\n",
       " 'E_DTM': 15,\n",
       " 'B_NUM': 16,\n",
       " 'I_NUM': 17,\n",
       " 'E_NUM': 18,\n",
       " 'B_TTL': 19,\n",
       " 'I_TTL': 20,\n",
       " 'E_TTL': 21,\n",
       " 'B_DES': 22,\n",
       " 'I_DES': 23,\n",
       " 'E_DES': 24,\n",
       " 'B_TRM': 25,\n",
       " 'I_TRM': 26,\n",
       " 'E_TRM': 27,\n",
       " 'B_BRN': 28,\n",
       " 'I_BRN': 29,\n",
       " 'E_BRN': 30,\n",
       " 'B_NAME': 31}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T06:52:27.981442Z",
     "iopub.status.busy": "2025-01-25T06:52:27.981152Z",
     "iopub.status.idle": "2025-01-25T06:55:03.491146Z",
     "shell.execute_reply": "2025-01-25T06:55:03.490160Z",
     "shell.execute_reply.started": "2025-01-25T06:52:27.981417Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                             tokens  \\\n",
      "0   0  [สภาสังคมสงเคราะห์แห่งประเทศ, ไทย, จี้, ศาล, ไ...   \n",
      "1   1  [สำนักงาน, องค์การ, พุทธศาสนิกสัมพันธ์, แห่ง, ...   \n",
      "2   2                           [ก่อน, กิจการ, พังพินาศ]   \n",
      "3   3              [หลัง, จาก, _, พยายาม, กระเสือกกระสน]   \n",
      "4   4                                   [หลัง, ล้มละลาย]   \n",
      "\n",
      "                                            ner_tags  \n",
      "0          [B_ORG, E_ORG, O, O, O, O, O, O, O, O, O]  \n",
      "1  [B_ORG, I_ORG, I_ORG, I_ORG, E_ORG, O, O, O, O...  \n",
      "2                                          [O, O, O]  \n",
      "3                                    [O, O, O, O, O]  \n",
      "4                                             [O, O]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def group_sentences_with_id(data, is_test=False):\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    sentence_id = 0\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        word, tag, cls = row['word'], row['tag'], row['class']\n",
    "        \n",
    "        if idx >= 200000 and not is_test:  # Limit test data to 200,000 rows\n",
    "            break\n",
    "\n",
    "        if tag not in tag_to_id:\n",
    "            continue\n",
    "\n",
    "        # Start new sentence if B_CLS found\n",
    "        if cls == 'B_CLS':\n",
    "            if sentence:  # Save previous sentence if exists\n",
    "                sentences.append({'sentence_id': sentence_id, 'words': sentence})\n",
    "                sentence_id += 1\n",
    "            sentence = [(word, tag)]\n",
    "\n",
    "        # Continue current sentence for I_CLS\n",
    "        elif cls == 'I_CLS':\n",
    "            sentence.append((word, tag))\n",
    "\n",
    "        # End sentence at E_CLS\n",
    "        elif cls == 'E_CLS':\n",
    "            sentence.append((word, tag))\n",
    "            sentences.append({'sentence_id': sentence_id, 'words': sentence})\n",
    "            sentence = []\n",
    "            sentence_id += 1\n",
    "\n",
    "        \n",
    "\n",
    "    # Add last sentence if exists\n",
    "    if sentence:\n",
    "        sentences.append({'sentence_id': sentence_id, 'words': sentence})\n",
    "\n",
    "    return sentences\n",
    "\n",
    "def create_dataframe(sentences):\n",
    "    data = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_id = sentence['sentence_id']\n",
    "        tokens = [word for word, tag in sentence['words']]\n",
    "        ner_tags = [tag for word, tag in sentence['words']]\n",
    "\n",
    "        data.append({'id': sentence_id, 'tokens': tokens, 'ner_tags': ner_tags})\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Create sentence groups with sentence_id\n",
    "train_sentences = group_sentences_with_id(train_data)\n",
    "eval_sentences = group_sentences_with_id(eval_data)\n",
    "test_sentences = group_sentences_with_id(test_data, is_test=True)\n",
    "\n",
    "# Convert to DataFrame\n",
    "train_df = create_dataframe(train_sentences)\n",
    "eval_df = create_dataframe(eval_sentences)\n",
    "test_df = create_dataframe(test_sentences)\n",
    "\n",
    "# Save to CSV (optional)\n",
    "train_df.to_csv('train_processed.csv', index=False)\n",
    "eval_df.to_csv('eval_processed.csv', index=False)\n",
    "test_df.to_csv('test_processed.csv', index=False)\n",
    "\n",
    "# Print sample to verify\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[สภาสังคมสงเคราะห์แห่งประเทศ, ไทย, จี้, ศาล, ไ...</td>\n",
       "      <td>[B_ORG, E_ORG, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[สำนักงาน, องค์การ, พุทธศาสนิกสัมพันธ์, แห่ง, ...</td>\n",
       "      <td>[B_ORG, I_ORG, I_ORG, I_ORG, E_ORG, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[ก่อน, กิจการ, พังพินาศ]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[หลัง, จาก, _, พยายาม, กระเสือกกระสน]</td>\n",
       "      <td>[O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[หลัง, ล้มละลาย]</td>\n",
       "      <td>[O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15831</th>\n",
       "      <td>15831</td>\n",
       "      <td>[ให้, ทัน, เพื่อน]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15832</th>\n",
       "      <td>15832</td>\n",
       "      <td>[หลังจาก, ทิ้ง, มา, นาน]</td>\n",
       "      <td>[O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15833</th>\n",
       "      <td>15833</td>\n",
       "      <td>[ส่วน, อนาคต, ต้อง, ฝึกซ้อม]</td>\n",
       "      <td>[O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15834</th>\n",
       "      <td>15834</td>\n",
       "      <td>[ให้, หนัก, มาก, กว่า, นี้]</td>\n",
       "      <td>[O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15835</th>\n",
       "      <td>15835</td>\n",
       "      <td>[เพราะ, คน, เล่น, เทควันโด, มี, คน, เก่ง, ๆ, _...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15836 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                             tokens  \\\n",
       "0          0  [สภาสังคมสงเคราะห์แห่งประเทศ, ไทย, จี้, ศาล, ไ...   \n",
       "1          1  [สำนักงาน, องค์การ, พุทธศาสนิกสัมพันธ์, แห่ง, ...   \n",
       "2          2                           [ก่อน, กิจการ, พังพินาศ]   \n",
       "3          3              [หลัง, จาก, _, พยายาม, กระเสือกกระสน]   \n",
       "4          4                                   [หลัง, ล้มละลาย]   \n",
       "...      ...                                                ...   \n",
       "15831  15831                                 [ให้, ทัน, เพื่อน]   \n",
       "15832  15832                           [หลังจาก, ทิ้ง, มา, นาน]   \n",
       "15833  15833                       [ส่วน, อนาคต, ต้อง, ฝึกซ้อม]   \n",
       "15834  15834                        [ให้, หนัก, มาก, กว่า, นี้]   \n",
       "15835  15835  [เพราะ, คน, เล่น, เทควันโด, มี, คน, เก่ง, ๆ, _...   \n",
       "\n",
       "                                                ner_tags  \n",
       "0              [B_ORG, E_ORG, O, O, O, O, O, O, O, O, O]  \n",
       "1      [B_ORG, I_ORG, I_ORG, I_ORG, E_ORG, O, O, O, O...  \n",
       "2                                              [O, O, O]  \n",
       "3                                        [O, O, O, O, O]  \n",
       "4                                                 [O, O]  \n",
       "...                                                  ...  \n",
       "15831                                          [O, O, O]  \n",
       "15832                                       [O, O, O, O]  \n",
       "15833                                       [O, O, O, O]  \n",
       "15834                                    [O, O, O, O, O]  \n",
       "15835                     [O, O, O, O, O, O, O, O, O, O]  \n",
       "\n",
       "[15836 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_df(df):\n",
    "  data_df = pd.DataFrame()\n",
    "  sentence_id = []\n",
    "  words = []\n",
    "  labels = []\n",
    "\n",
    "  for sentence in range(len(df)):\n",
    "    for token in range(len(df['tokens'][sentence])):\n",
    "      sentence_id.append(sentence)\n",
    "      words.append(df['tokens'][sentence][token])\n",
    "      labels.append(df['ner_tags'][sentence][token]) #Map 0 to \"O\", 1 to \"B_BRN\"\n",
    "\n",
    "  return pd.DataFrame(\n",
    "      {\"sentence_id\": sentence_id, \"words\": words, \"labels\": labels}\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>สภาสังคมสงเคราะห์แห่งประเทศ</td>\n",
       "      <td>B_ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ไทย</td>\n",
       "      <td>E_ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>จี้</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ศาล</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ไฟเขียว</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                        words labels\n",
       "0            0  สภาสังคมสงเคราะห์แห่งประเทศ  B_ORG\n",
       "1            0                          ไทย  E_ORG\n",
       "2            0                          จี้      O\n",
       "3            0                          ศาล      O\n",
       "4            0                      ไฟเขียว      O"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data = convert_data_to_df(eval_df)\n",
    "train_data = convert_data_to_df(train_df)\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_mapping = {\n",
    "    'O': 0,\n",
    "    'B_ORG': 1, \n",
    "    'B_PER': 2,\n",
    "    'B_LOC': 3,\n",
    "    'B_MEA': 4,\n",
    "    'I_DTM': 5,\n",
    "    'I_ORG': 6,\n",
    "    'E_ORG': 7,\n",
    "    'I_PER': 8,\n",
    "    'B_TTL': 9,\n",
    "    'E_PER': 10,\n",
    "    'B_DES': 11,\n",
    "    'E_LOC': 12,\n",
    "    'B_DTM': 13,\n",
    "    'B_NUM': 14,\n",
    "    'I_MEA': 15,\n",
    "    'E_DTM': 16,\n",
    "    'E_MEA': 17,\n",
    "    'I_LOC': 18,\n",
    "    'I_DES': 19,\n",
    "    'E_DES': 20,\n",
    "    'I_NUM': 21,\n",
    "    'E_NUM': 22,\n",
    "    'B_TRM': 23,\n",
    "    'B_BRN': 24,\n",
    "    'I_TRM': 25,\n",
    "    'E_TRM': 26,\n",
    "    'I_TTL': 27,\n",
    "    'I_BRN': 28,\n",
    "    'E_BRN': 29,\n",
    "    'E_TTL': 30,\n",
    "    'B_NAME': 31\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: simpletransformers in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.70.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from simpletransformers) (1.26.4)\n",
      "Requirement already satisfied: requests in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from simpletransformers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.47.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from simpletransformers) (4.66.5)\n",
      "Requirement already satisfied: regex in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from simpletransformers) (2024.7.24)\n",
      "Requirement already satisfied: transformers>=4.31.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from simpletransformers) (4.48.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from simpletransformers) (3.2.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from simpletransformers) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from simpletransformers) (1.5.0)\n",
      "Requirement already satisfied: seqeval in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from simpletransformers) (1.2.2)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from simpletransformers) (2.17.1)\n",
      "Requirement already satisfied: tensorboardx in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from simpletransformers) (2.6.2.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from simpletransformers) (2.2.2)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from simpletransformers) (0.21.0)\n",
      "Requirement already satisfied: wandb>=0.10.32 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from simpletransformers) (0.19.4)\n",
      "Requirement already satisfied: streamlit in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from simpletransformers) (1.41.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from simpletransformers) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\potij\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.47.0->simpletransformers) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=4.31.0->simpletransformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=4.31.0->simpletransformers) (0.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=4.31.0->simpletransformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=4.31.0->simpletransformers) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=4.31.0->simpletransformers) (0.5.2)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\potij\\appdata\\roaming\\python\\python312\\site-packages (from wandb>=0.10.32->simpletransformers) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (4.25.5)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\potij\\appdata\\roaming\\python\\python312\\site-packages (from wandb>=0.10.32->simpletransformers) (5.9.8)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (2.8.2)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (2.20.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (1.3.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (72.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->simpletransformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->simpletransformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->simpletransformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->simpletransformers) (2024.7.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets->simpletransformers) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets->simpletransformers) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets->simpletransformers) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets->simpletransformers) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->simpletransformers) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets->simpletransformers) (3.11.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->simpletransformers) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->simpletransformers) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->simpletransformers) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->simpletransformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->simpletransformers) (3.5.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit->simpletransformers) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit->simpletransformers) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit->simpletransformers) (5.5.0)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit->simpletransformers) (10.3.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit->simpletransformers) (13.7.1)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit->simpletransformers) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit->simpletransformers) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit->simpletransformers) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit->simpletransformers) (6.0.0)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit->simpletransformers) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\potij\\appdata\\roaming\\python\\python312\\site-packages (from streamlit->simpletransformers) (6.4.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard->simpletransformers) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard->simpletransformers) (1.66.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard->simpletransformers) (3.7)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard->simpletransformers) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard->simpletransformers) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard->simpletransformers) (3.0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (1.23.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets->simpletransformers) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets->simpletransformers) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets->simpletransformers) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets->simpletransformers) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets->simpletransformers) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets->simpletransformers) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets->simpletransformers) (1.18.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=2.6->wandb>=0.10.32->simpletransformers) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=2.6->wandb>=0.10.32->simpletransformers) (2.20.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\potij\\appdata\\roaming\\python\\python312\\site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (2.1.5)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.22.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->simpletransformers) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.ner import NERModel\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B_ORG',\n",
       " 'I_ORG',\n",
       " 'E_ORG',\n",
       " 'B_PER',\n",
       " 'I_PER',\n",
       " 'E_PER',\n",
       " 'B_LOC',\n",
       " 'I_LOC',\n",
       " 'E_LOC',\n",
       " 'B_MEA',\n",
       " 'I_MEA',\n",
       " 'E_MEA',\n",
       " 'B_DTM',\n",
       " 'I_DTM',\n",
       " 'E_DTM',\n",
       " 'B_NUM',\n",
       " 'I_NUM',\n",
       " 'E_NUM',\n",
       " 'B_TTL',\n",
       " 'I_TTL',\n",
       " 'E_TTL',\n",
       " 'B_DES',\n",
       " 'I_DES',\n",
       " 'E_DES',\n",
       " 'B_TRM',\n",
       " 'I_TRM',\n",
       " 'E_TRM',\n",
       " 'B_BRN',\n",
       " 'I_BRN',\n",
       " 'E_BRN',\n",
       " 'B_NAME']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tag_to_id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from simpletransformers.ner import NERModel\n",
    "\n",
    "# 2. Create directories\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "os.makedirs('cache', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_args = {\n",
    "    'output_dir': 'outputs/ner_model',\n",
    "    'cache_dir': 'cache',\n",
    "    'num_train_epochs': 5,\n",
    "    'learning_rate': 1e-4,\n",
    "    'max_seq_length': 128,\n",
    "    'train_batch_size': 16,\n",
    "    'eval_batch_size': 16,\n",
    "    'overwrite_output_dir': True,\n",
    "    'save_eval_checkpoints': False,\n",
    "    'save_model_every_epoch': True\n",
    "}\n",
    "\n",
    "# 5. Initialize and train model\n",
    "model = NERModel(\n",
    "    \"bert\",\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    args=model_args,\n",
    "    labels=list(tag_to_id.keys())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>สภาสังคมสงเคราะห์แห่งประเทศ</td>\n",
       "      <td>B_ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ไทย</td>\n",
       "      <td>E_ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>จี้</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ศาล</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ไฟเขียว</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194533</th>\n",
       "      <td>15835</td>\n",
       "      <td>คน</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194534</th>\n",
       "      <td>15835</td>\n",
       "      <td>เก่ง</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194535</th>\n",
       "      <td>15835</td>\n",
       "      <td>ๆ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194536</th>\n",
       "      <td>15835</td>\n",
       "      <td>_</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194537</th>\n",
       "      <td>15835</td>\n",
       "      <td>มาก</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194538 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id                        words labels\n",
       "0                 0  สภาสังคมสงเคราะห์แห่งประเทศ  B_ORG\n",
       "1                 0                          ไทย  E_ORG\n",
       "2                 0                          จี้      O\n",
       "3                 0                          ศาล      O\n",
       "4                 0                      ไฟเขียว      O\n",
       "...             ...                          ...    ...\n",
       "194533        15835                           คน      O\n",
       "194534        15835                         เก่ง      O\n",
       "194535        15835                            ๆ      O\n",
       "194536        15835                            _      O\n",
       "194537        15835                          มาก      O\n",
       "\n",
       "[194538 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>สภาสังคมสงเคราะห์แห่งประเทศ</td>\n",
       "      <td>B_ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ไทย</td>\n",
       "      <td>E_ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>จี้</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ศาล</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ไฟเขียว</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194533</th>\n",
       "      <td>15835</td>\n",
       "      <td>คน</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194534</th>\n",
       "      <td>15835</td>\n",
       "      <td>เก่ง</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194535</th>\n",
       "      <td>15835</td>\n",
       "      <td>ๆ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194536</th>\n",
       "      <td>15835</td>\n",
       "      <td>_</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194537</th>\n",
       "      <td>15835</td>\n",
       "      <td>มาก</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194538 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id                        words labels\n",
       "0                 0  สภาสังคมสงเคราะห์แห่งประเทศ  B_ORG\n",
       "1                 0                          ไทย  E_ORG\n",
       "2                 0                          จี้      O\n",
       "3                 0                          ศาล      O\n",
       "4                 0                      ไฟเขียว      O\n",
       "...             ...                          ...    ...\n",
       "194533        15835                           คน      O\n",
       "194534        15835                         เก่ง      O\n",
       "194535        15835                            ๆ      O\n",
       "194536        15835                            _      O\n",
       "194537        15835                          มาก      O\n",
       "\n",
       "[194538 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_st_format(df):\n",
    "    st_data = []\n",
    "    sentence_id = 0\n",
    "    current_sentence = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        word, tag = row['word'], row['tag']\n",
    "        if row['class'] == 'B_CLS':\n",
    "            if current_sentence:\n",
    "                st_data.extend([(sentence_id, word, tag) for word, tag in current_sentence])\n",
    "                sentence_id += 1\n",
    "            current_sentence = [(word, tag)]\n",
    "        else:\n",
    "            current_sentence.append((word, tag))\n",
    "            \n",
    "    return pd.DataFrame([\n",
    "        [sent_id, word, tag] for sent_id, word, tag in st_data\n",
    "    ], columns=['sentence_id', 'words', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'word'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'word'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_st_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m eval_df \u001b[38;5;241m=\u001b[39m convert_to_st_format(eval_data)\n",
      "Cell \u001b[1;32mIn[37], line 7\u001b[0m, in \u001b[0;36mconvert_to_st_format\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      4\u001b[0m current_sentence \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m----> 7\u001b[0m     word, tag \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mword\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtag\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB_CLS\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m current_sentence:\n",
      "File \u001b[1;32mc:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'word'"
     ]
    }
   ],
   "source": [
    "train_df = convert_to_st_format(train_data)\n",
    "eval_df = convert_to_st_format(eval_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:21<00:00,  1.37it/s]\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "runs is not a directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\simpletransformers\\ner\\ner_model.py:513\u001b[0m, in \u001b[0;36mNERModel.train_model\u001b[1;34m(self, train_data, output_dir, show_running_loss, args, eval_data, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_and_cache_examples(train_data)\n\u001b[0;32m    511\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 513\u001b[0m global_step, training_details \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_running_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_running_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m    523\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Training of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m model complete. Saved to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel_type, output_dir\n\u001b[0;32m    526\u001b[0m     )\n\u001b[0;32m    527\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\simpletransformers\\ner\\ner_model.py:550\u001b[0m, in \u001b[0;36mNERModel.train\u001b[1;34m(self, train_dataset, output_dir, show_running_loss, eval_data, test_data, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    547\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    548\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m--> 550\u001b[0m tb_writer \u001b[38;5;241m=\u001b[39m \u001b[43mSummaryWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensorboard_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m train_sampler \u001b[38;5;241m=\u001b[39m RandomSampler(train_dataset)\n\u001b[0;32m    552\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m    553\u001b[0m     train_dataset,\n\u001b[0;32m    554\u001b[0m     sampler\u001b[38;5;241m=\u001b[39mtrain_sampler,\n\u001b[0;32m    555\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mtrain_batch_size,\n\u001b[0;32m    556\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_num_workers,\n\u001b[0;32m    557\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:250\u001b[0m, in \u001b[0;36mSummaryWriter.__init__\u001b[1;34m(self, log_dir, comment, purge_step, max_queue, flush_secs, filename_suffix)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# Initialize the file writers, but they can be cleared out on close\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# and recreated later as needed.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_writer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_writers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 250\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_file_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# Create default bins for histograms, see generate_testdata.py in tensorflow/tensorboard\u001b[39;00m\n\u001b[0;32m    253\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-12\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:265\u001b[0m, in \u001b[0;36mSummaryWriter._get_file_writer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the default FileWriter instance. Recreates it if closed.\"\"\"\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_writers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_writer \u001b[38;5;241m=\u001b[39m \u001b[43mFileWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush_secs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename_suffix\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_writers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_writer\u001b[38;5;241m.\u001b[39mget_logdir(): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_writer}\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpurge_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:76\u001b[0m, in \u001b[0;36mFileWriter.__init__\u001b[1;34m(self, log_dir, max_queue, flush_secs, filename_suffix)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Sometimes PosixPath is passed in and we need to coerce it to\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# a string in all cases\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# TODO: See if we can remove this in the future if we are\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# actually the ones passing in a PosixPath\u001b[39;00m\n\u001b[0;32m     75\u001b[0m log_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(log_dir)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent_writer \u001b[38;5;241m=\u001b[39m \u001b[43mEventFileWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflush_secs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename_suffix\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:72\u001b[0m, in \u001b[0;36mEventFileWriter.__init__\u001b[1;34m(self, logdir, max_queue_size, flush_secs, filename_suffix)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a `EventFileWriter` and an event file to write to.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03mOn construction the summary writer creates a new event file in `logdir`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m    pending events and summaries to disk.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logdir \u001b[38;5;241m=\u001b[39m logdir\n\u001b[1;32m---> 72\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogdir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_name \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m     75\u001b[0m         logdir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;241m+\u001b[39m filename_suffix\n\u001b[0;32m     85\u001b[0m )  \u001b[38;5;66;03m# noqa E128\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_general_file_writer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mGFile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:513\u001b[0m, in \u001b[0;36mrecursive_create_dir_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.gfile.makedirs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_create_dir_v2\u001b[39m(path):\n\u001b[0;32m    503\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a directory and all parent/intermediate directories.\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \n\u001b[0;32m    505\u001b[0m \u001b[38;5;124;03m  It succeeds if path already exists and is writable.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m    errors.OpError: If the operation fails.\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 513\u001b[0m   \u001b[43m_pywrap_file_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecursivelyCreateDir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: runs is not a directory"
     ]
    }
   ],
   "source": [
    "model.train_model(train_data, eval_data=eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from simpletransformers.ner import NERModel\n",
    "# import pandas as pd\n",
    "# model = NERModel(\n",
    "#     \"bert\", \n",
    "#     \"bert-base-multilingual-cased\", \n",
    "#     labels=tag_mapping,\n",
    "#     args={\"overwrite_output_dir\": True, \"train_batch_size\": 32, \"num_train_epochs\": 3},\n",
    "#     use_cuda=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train_model(train_data, eval_data=eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentences(tokens, tokens_per_sentence=26):\n",
    "    sentences = []\n",
    "    for i in range(0, len(tokens), tokens_per_sentence):\n",
    "        # Slice the tokens list into chunks of the specified size\n",
    "        sentence = tokens[i:i + tokens_per_sentence]\n",
    "        sentences.append(sentence)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tokens'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m             processed_data\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m: sentence, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mner_tags\u001b[39m\u001b[38;5;124m'\u001b[39m: tag})\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(processed_data)\n\u001b[1;32m---> 14\u001b[0m train_df_prepared \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data_for_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m eval_df_prepared \u001b[38;5;241m=\u001b[39m prepare_data_for_model(eval_df)\n",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m, in \u001b[0;36mprepare_data_for_model\u001b[1;34m(data, tokens_per_sentence)\u001b[0m\n\u001b[0;32m      2\u001b[0m processed_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m----> 4\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m     ner_tags \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mner_tags\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m split_into_sentences(tokens, tokens_per_sentence)\n",
      "File \u001b[1;32mc:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tokens'"
     ]
    }
   ],
   "source": [
    "def prepare_data_for_model(data, tokens_per_sentence=26):\n",
    "    processed_data = []\n",
    "    for _, row in data.iterrows():\n",
    "        tokens = row['tokens']\n",
    "        ner_tags = row['ner_tags']\n",
    "        sentences = split_into_sentences(tokens, tokens_per_sentence)\n",
    "        tags = split_into_sentences(ner_tags, tokens_per_sentence)\n",
    "\n",
    "        for sentence, tag in zip(sentences, tags):\n",
    "            processed_data.append({'tokens': sentence, 'ner_tags': tag})\n",
    "\n",
    "    return pd.DataFrame(processed_data)\n",
    "\n",
    "train_df_prepared = prepare_data_for_model(train_df)\n",
    "eval_df_prepared = prepare_data_for_model(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[โฆษก, กอส., ตำหนิ, แมนฯ, _, ซิตี้]</td>\n",
       "      <td>[O, B_ORG, O, B_ORG, I_ORG, E_ORG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[โฆษก, หนังสือพิมพ์, _, ASTV, ตำหนิ, สพก.]</td>\n",
       "      <td>[O, B_ORG, I_ORG, E_ORG, O, B_ORG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ที่, บิดเบือน, ข้อเท็จจริง, ต่อ, คณะ, ฑูต, ต่...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[แต่, ยัง, ยินดี]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ที่, จะ, สนับสนุน, การ, ดำเนินการ, เกี่ยวกับ,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16472</th>\n",
       "      <td>[เพราะ, ยัง, ไม่, เป็น]</td>\n",
       "      <td>[O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16473</th>\n",
       "      <td>[ที่, แน่ชัด]</td>\n",
       "      <td>[O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16474</th>\n",
       "      <td>[ว่า, ตลาด, หุ้น, จะ, บวก, ขึ้น, ได้, ต่อเนื่อ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B_TTL, B_PER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16475</th>\n",
       "      <td>[นาง, ศาสตรา, _, เทียนทอง, _, กรรมการ, และ, ผู...</td>\n",
       "      <td>[B_TTL, B_PER, I_PER, E_PER, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16476</th>\n",
       "      <td>[ที่, ประชุม, คณะ, กรรมการ, _, สามารถ, ฯ, ใน, ...</td>\n",
       "      <td>[O, O, O, O, O, B_ORG, E_ORG, O, B_DTM, E_DTM,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16477 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0                    [โฆษก, กอส., ตำหนิ, แมนฯ, _, ซิตี้]   \n",
       "1             [โฆษก, หนังสือพิมพ์, _, ASTV, ตำหนิ, สพก.]   \n",
       "2      [ที่, บิดเบือน, ข้อเท็จจริง, ต่อ, คณะ, ฑูต, ต่...   \n",
       "3                                      [แต่, ยัง, ยินดี]   \n",
       "4      [ที่, จะ, สนับสนุน, การ, ดำเนินการ, เกี่ยวกับ,...   \n",
       "...                                                  ...   \n",
       "16472                            [เพราะ, ยัง, ไม่, เป็น]   \n",
       "16473                                      [ที่, แน่ชัด]   \n",
       "16474  [ว่า, ตลาด, หุ้น, จะ, บวก, ขึ้น, ได้, ต่อเนื่อ...   \n",
       "16475  [นาง, ศาสตรา, _, เทียนทอง, _, กรรมการ, และ, ผู...   \n",
       "16476  [ที่, ประชุม, คณะ, กรรมการ, _, สามารถ, ฯ, ใน, ...   \n",
       "\n",
       "                                                ner_tags  \n",
       "0                     [O, B_ORG, O, B_ORG, I_ORG, E_ORG]  \n",
       "1                     [O, B_ORG, I_ORG, E_ORG, O, B_ORG]  \n",
       "2                   [O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "3                                              [O, O, O]  \n",
       "4                      [O, O, O, O, O, O, O, O, O, O, O]  \n",
       "...                                                  ...  \n",
       "16472                                       [O, O, O, O]  \n",
       "16473                                             [O, O]  \n",
       "16474  [O, O, O, O, O, O, O, O, O, O, O, B_TTL, B_PER...  \n",
       "16475  [B_TTL, B_PER, I_PER, E_PER, O, O, O, O, O, O,...  \n",
       "16476  [O, O, O, O, O, B_ORG, E_ORG, O, B_DTM, E_DTM,...  \n",
       "\n",
       "[16477 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03795_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03795_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03795_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03795_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03795_4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213086</th>\n",
       "      <td>04276_844</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213087</th>\n",
       "      <td>04276_845</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213088</th>\n",
       "      <td>04276_846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213089</th>\n",
       "      <td>04276_847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213090</th>\n",
       "      <td>04276_848</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213091 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  ne\n",
       "0         03795_0   0\n",
       "1         03795_1   0\n",
       "2         03795_2   0\n",
       "3         03795_3   0\n",
       "4         03795_4   6\n",
       "...           ...  ..\n",
       "213086  04276_844   0\n",
       "213087  04276_845   0\n",
       "213088  04276_846   0\n",
       "213089  04276_847   0\n",
       "213090  04276_848   0\n",
       "\n",
       "[213091 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pd.read_csv('sample_submission.csv')\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'numeric_tag'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'numeric_tag'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mne\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnumeric_tag\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      2\u001b[0m out\n",
      "File \u001b[1;32mc:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'numeric_tag'"
     ]
    }
   ],
   "source": [
    "out['ne'] = test_df['numeric_tag']\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "out.to_csv('sample_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 10905660,
     "sourceId": 91251,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
