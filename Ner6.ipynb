{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T06:51:58.060493Z",
     "iopub.status.busy": "2025-01-25T06:51:58.060045Z",
     "iopub.status.idle": "2025-01-25T06:52:25.981084Z",
     "shell.execute_reply": "2025-01-25T06:52:25.980159Z",
     "shell.execute_reply.started": "2025-01-25T06:51:58.060466Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to train_data.csv\n",
      "Saved processed data to eval_data.csv\n",
      "Saved processed data to test_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ฟังก์ชันสำหรับอ่านไฟล์จากโฟลเดอร์ตามลำดับ\n",
    "def read_data_from_folder(folder_path):\n",
    "    data = []\n",
    "    # เรียงลำดับชื่อไฟล์ตามลำดับตัวเลข\n",
    "    file_names = sorted(os.listdir(folder_path))\n",
    "    for file_name in file_names:\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                for line in file:\n",
    "                    line = line.strip()\n",
    "                    if line:  # ข้ามแถวว่าง\n",
    "                        parts = line.split(\"\\t\")\n",
    "                        if len(parts) == 4:  # ถ้ามี 4 คอลัมน์\n",
    "                            data.append(parts)\n",
    "                        elif len(parts) == 3:  # ถ้ามี 3 คอลัมน์ เติมค่า default สำหรับ `tag`\n",
    "                            parts.insert(2, \"O\")  # ใส่ค่า \"O\" ที่ตำแหน่ง index 2\n",
    "                            data.append(parts)\n",
    "                        else:\n",
    "                            print(f\"Invalid line in {file_name}: {line}\")\n",
    "    return data\n",
    "\n",
    "# ฟังก์ชันสำหรับรวบรวมและบันทึกข้อมูล\n",
    "def process_and_save_data(input_folder, output_file):\n",
    "    data = read_data_from_folder(input_folder)\n",
    "    df = pd.DataFrame(data, columns=[\"word\", \"pos\", \"tag\", \"class\"])\n",
    "    df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Saved processed data to {output_file}\")\n",
    "\n",
    "# โฟลเดอร์ข้อมูล (แก้ไขให้ตรงกับโครงสร้างใน Kaggle)\n",
    "train_folder = \"train\"\n",
    "test_folder = \"test\"\n",
    "eval_folder = \"eval\"\n",
    "\n",
    "# เซฟข้อมูลเป็นไฟล์ CSV\n",
    "process_and_save_data(train_folder, \"train_data.csv\")\n",
    "process_and_save_data(eval_folder, \"eval_data.csv\")\n",
    "process_and_save_data(test_folder, \"test_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T06:52:25.982813Z",
     "iopub.status.busy": "2025-01-25T06:52:25.982526Z",
     "iopub.status.idle": "2025-01-25T06:52:27.979665Z",
     "shell.execute_reply": "2025-01-25T06:52:27.978471Z",
     "shell.execute_reply.started": "2025-01-25T06:52:25.982789Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          word pos    tag  class\n",
      "0  สภาสังคมสงเคราะห์แห่งประเทศ  NN  B_ORG  B_CLS\n",
      "1                          ไทย  NN  E_ORG  I_CLS\n",
      "2                          จี้  VV      O  I_CLS\n",
      "3                          ศาล  NN      O  I_CLS\n",
      "4                      ไฟเขียว  VV      O  I_CLS\n",
      "    word pos    tag  class\n",
      "0   โฆษก  NN      O  B_CLS\n",
      "1   กอส.  NN  B_ORG  I_CLS\n",
      "2  ตำหนิ  VV      O  I_CLS\n",
      "3   แมนฯ  NN  B_ORG  I_CLS\n",
      "4      _  NN  I_ORG  I_CLS\n",
      "     word pos tag  class\n",
      "0     รัฐ  NN   O  B_CLS\n",
      "1  ถังแตก  VV   O  I_CLS\n",
      "2     วิก  NN   O  I_CLS\n",
      "3       _  NN   O  I_CLS\n",
      "4       7  NN   O  I_CLS\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# โหลดข้อมูล\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "eval_data = pd.read_csv('eval_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# ตรวจสอบตัวอย่างข้อมูล\n",
    "print(train_data.head())\n",
    "print(eval_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T06:52:27.981442Z",
     "iopub.status.busy": "2025-01-25T06:52:27.981152Z",
     "iopub.status.idle": "2025-01-25T06:55:03.491146Z",
     "shell.execute_reply": "2025-01-25T06:55:03.490160Z",
     "shell.execute_reply.started": "2025-01-25T06:52:27.981417Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def group_sentences(data):\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        word, tag, cls = row['word'], row['tag'], row['class']\n",
    "        \n",
    "        # Start new sentence if B_CLS found\n",
    "        if cls == 'B_CLS':\n",
    "            if sentence:  # Save previous sentence if exists\n",
    "                sentences.append(sentence)\n",
    "            sentence = [(word, tag)]\n",
    "            \n",
    "        # Continue current sentence for I_CLS\n",
    "        elif cls == 'I_CLS':\n",
    "            sentence.append((word, tag))\n",
    "            \n",
    "        # End sentence at E_CLS\n",
    "        elif cls == 'E_CLS':\n",
    "            sentence.append((word, tag))\n",
    "            sentences.append(sentence)\n",
    "            sentence = []\n",
    "    \n",
    "    # Add last sentence if exists\n",
    "    if sentence:\n",
    "        sentences.append(sentence)\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "# Create sentence groups\n",
    "train_sentences = group_sentences(train_data)\n",
    "eval_sentences = group_sentences(eval_data) \n",
    "test_sentences = group_sentences(test_data)\n",
    "\n",
    "# Print sample to verify\n",
    "print(\"Sample sentence:\")\n",
    "print(train_sentences[0])\n",
    "print(f\"\\nTotal sentences: {len(train_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T06:55:03.492451Z",
     "iopub.status.busy": "2025-01-25T06:55:03.492133Z",
     "iopub.status.idle": "2025-01-25T06:55:26.063371Z",
     "shell.execute_reply": "2025-01-25T06:55:26.062191Z",
     "shell.execute_reply.started": "2025-01-25T06:55:03.492426Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.48.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\potij\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.20.1+cpu)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1+cpu)\n",
      "Requirement already satisfied: filelock in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\potij\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U transformers datasets\n",
    "%pip install sentencepiece\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T06:55:26.064995Z",
     "iopub.status.busy": "2025-01-25T06:55:26.064624Z",
     "iopub.status.idle": "2025-01-25T06:55:52.703842Z",
     "shell.execute_reply": "2025-01-25T06:55:52.702898Z",
     "shell.execute_reply.started": "2025-01-25T06:55:26.064967Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# โหลด Tokenizer และ Model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lst-nectec/HoogBERTa-NER-lst20\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"lst-nectec/HoogBERTa-NER-lst20\").to(\"cuda\")\n",
    "\n",
    "\n",
    "# ดูรายละเอียดโมเดล (เช่น จำนวน Labels)\n",
    "print(model.config.num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T06:55:52.705357Z",
     "iopub.status.busy": "2025-01-25T06:55:52.704748Z",
     "iopub.status.idle": "2025-01-25T06:56:54.260095Z",
     "shell.execute_reply": "2025-01-25T06:56:54.259235Z",
     "shell.execute_reply.started": "2025-01-25T06:55:52.705331Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenize ข้อมูล\n",
    "def tokenize_and_align_labels(sentences):\n",
    "    tokenized_inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        words, tags = zip(*sentence)\n",
    "        tokenized_input = tokenizer(list(words), is_split_into_words=True, truncation=True, padding=True, max_length=128)\n",
    "        word_ids = tokenized_input.word_ids()  # ติดตาม index ของคำ\n",
    "        label_ids = []\n",
    "        \n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                label_ids.append(-100)  # สำหรับตำแหน่ง padding\n",
    "            else:\n",
    "                label_ids.append(get_tag_id(tags[word_id]))  # ใช้ฟังก์ชัน safe mapping\n",
    "        tokenized_inputs.append(tokenized_input)\n",
    "        labels.append(label_ids)\n",
    "    \n",
    "    return tokenized_inputs, labels\n",
    "\n",
    "# Read tag mapping from CSV\n",
    "tag_mapping_df = pd.read_csv('tag_list.csv')\n",
    "\n",
    "# Create mapping dictionaries\n",
    "tag_to_id = dict(zip(tag_mapping_df['tag'], tag_mapping_df['class']))\n",
    "id_to_tag = dict(zip(tag_mapping_df['class'], tag_mapping_df['tag']))\n",
    "\n",
    "# Create safe mapping function with default value 0\n",
    "def get_tag_id(tag):\n",
    "    return tag_to_id.get(tag, 0)  # Returns 0 for unknown tags\n",
    "\n",
    "# Tokenize train, eval, และ test\n",
    "train_encodings, train_labels = tokenize_and_align_labels(train_sentences)\n",
    "eval_encodings, eval_labels = tokenize_and_align_labels(eval_sentences)\n",
    "test_encodings, test_labels = tokenize_and_align_labels(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T06:56:54.263030Z",
     "iopub.status.busy": "2025-01-25T06:56:54.262764Z",
     "iopub.status.idle": "2025-01-25T06:56:54.270013Z",
     "shell.execute_reply": "2025-01-25T06:56:54.269051Z",
     "shell.execute_reply.started": "2025-01-25T06:56:54.263008Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample mappings:\n",
      "\n",
      "Tag to ID examples:\n",
      "{'O': 0, 'B_ORG': 1, 'B_PER': 2, 'B_LOC': 3, 'B_MEA': 4}\n",
      "\n",
      "ID to Tag examples:\n",
      "{0: 'O', 1: 'B_ORG', 2: 'B_PER', 3: 'B_LOC', 4: 'B_MEA'}\n",
      "\n",
      "Unknown tag test:\n",
      "Unknown tag 'TEST' maps to: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample mappings:\")\n",
    "print(\"\\nTag to ID examples:\")\n",
    "print({k: v for k, v in list(tag_to_id.items())[:5]})\n",
    "print(\"\\nID to Tag examples:\")\n",
    "print({k: v for k, v in list(id_to_tag.items())[:5]})\n",
    "\n",
    "# Test unknown tag handling\n",
    "print(\"\\nUnknown tag test:\")\n",
    "print(f\"Unknown tag 'TEST' maps to: {get_tag_id('TEST')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T06:56:54.272164Z",
     "iopub.status.busy": "2025-01-25T06:56:54.271889Z",
     "iopub.status.idle": "2025-01-25T06:56:54.296745Z",
     "shell.execute_reply": "2025-01-25T06:56:54.295694Z",
     "shell.execute_reply.started": "2025-01-25T06:56:54.272142Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. Modified NERDataset with proper padding\n",
    "class NERDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels, max_length=128):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get current encoding and labels\n",
    "        encoding = self.encodings[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Pad input_ids and attention_mask\n",
    "        input_ids = encoding['input_ids']\n",
    "        attention_mask = encoding['attention_mask']\n",
    "        \n",
    "        # Ensure consistent length\n",
    "        if len(input_ids) > self.max_length:\n",
    "            input_ids = input_ids[:self.max_length]\n",
    "            attention_mask = attention_mask[:self.max_length]\n",
    "            label = label[:self.max_length]\n",
    "        else:\n",
    "            # Pad sequences\n",
    "            padding_length = self.max_length - len(input_ids)\n",
    "            input_ids = input_ids + [tokenizer.pad_token_id] * padding_length\n",
    "            attention_mask = attention_mask + [0] * padding_length\n",
    "            label = label + [-100] * padding_length\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids),\n",
    "            'attention_mask': torch.tensor(attention_mask),\n",
    "            'labels': torch.tensor(label)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "\n",
    "# 2. Create datasets with fixed length\n",
    "train_dataset = NERDataset(train_encodings, train_labels)\n",
    "eval_dataset = NERDataset(eval_encodings, eval_labels)\n",
    "test_dataset = NERDataset(test_encodings, test_labels)\n",
    "\n",
    "# 3. Create DataLoader with fixed batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=16)\n",
    "# DataLoader สำหรับ test ต้องไม่มีการสุ่ม\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=16,\n",
    "    shuffle=False,  # ตั้งค่าเป็น False เพื่อรักษาลำดับ\n",
    "    drop_last=False  # ไม่ทิ้ง batch สุดท้ายแม้จะไม่เต็ม batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# คำนวณจำนวนตัวอย่างที่ต้องการ (20% ของ train_loader)\n",
    "num_samples = int(len(train_dataset) * 0.1)\n",
    "\n",
    "# สุ่มเลือกตัวอย่าง\n",
    "indices = torch.randperm(len(train_dataset)).tolist()[:num_samples]\n",
    "\n",
    "# สร้าง Subset ของ train_dataset\n",
    "subset_train_dataset = Subset(train_dataset, indices)\n",
    "\n",
    "# สร้าง DataLoader ใหม่สำหรับ subset\n",
    "train_loader = DataLoader(subset_train_dataset, batch_size=16, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T06:56:54.297952Z",
     "iopub.status.busy": "2025-01-25T06:56:54.297586Z",
     "iopub.status.idle": "2025-01-25T06:56:54.308970Z",
     "shell.execute_reply": "2025-01-25T06:56:54.308057Z",
     "shell.execute_reply.started": "2025-01-25T06:56:54.297925Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "def evaluate(model, dataloader, id_to_tag):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(eval_loader):\n",
    "            input_ids = batch['input_ids'].to(\"cuda\")\n",
    "            \n",
    "            labels = batch['labels'].cpu().numpy()\n",
    "            outputs = model(input_ids)\n",
    "\n",
    "            # print(outputs.logits.shape)\n",
    "            predictions = torch.argmax(outputs.logits, dim=2).cpu().numpy()\n",
    "            # print(predictions)\n",
    "                \n",
    "            # Process each sequence in the batch\n",
    "            for label, pred in zip(labels, predictions):\n",
    "                # Filter out padding (-100)\n",
    "                valid_indices = label != -100\n",
    "                true_sequence = label[valid_indices]\n",
    "                pred_sequence = pred[valid_indices]\n",
    "                \n",
    "                # Convert to tag names\n",
    "                true_tags = [id_to_tag[l] for l in true_sequence]\n",
    "                pred_tags = [id_to_tag[p] for p in pred_sequence]\n",
    "                \n",
    "                true_labels.append(true_tags)\n",
    "                pred_labels.append(pred_tags)\n",
    "    \n",
    "    # Convert to binary format using MultiLabelBinarizer\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    true_binary = mlb.fit_transform([[tag] for tag in sum(true_labels, [])])\n",
    "    pred_binary = mlb.transform([[tag] for tag in sum(pred_labels, [])])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    f1 = f1_score(true_binary, pred_binary, average='macro')\n",
    "    report = classification_report(true_binary, pred_binary, \n",
    "                                target_names=mlb.classes_)\n",
    "    \n",
    "    return f1, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T06:56:54.310125Z",
     "iopub.status.busy": "2025-01-25T06:56:54.309831Z",
     "iopub.status.idle": "2025-01-25T06:56:54.329334Z",
     "shell.execute_reply": "2025-01-25T06:56:54.328248Z",
     "shell.execute_reply.started": "2025-01-25T06:56:54.310091Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\potij\\AppData\\Local\\Temp\\ipykernel_43860\\2508763736.py:6: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "c:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. Initialize gradient scaler for mixed precision\n",
    "scaler = GradScaler()\n",
    "\n",
    "# 2. Setup optimized parameters\n",
    "batch_size = 64  # increased batch size\n",
    "accumulation_steps = 2  # gradient accumulation\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1.0  # gradient clipping\n",
    "warmup_ratio = 0.1\n",
    "\n",
    "# 3. Setup optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-3)\n",
    "total_steps = len(train_loader) * num_epochs // accumulation_steps\n",
    "warmup_steps = int(total_steps * warmup_ratio)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T06:56:54.330762Z",
     "iopub.status.busy": "2025-01-25T06:56:54.330420Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/13800 [00:00<?, ?it/s]C:\\Users\\potij\\AppData\\Local\\Temp\\ipykernel_43860\\618387287.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 1: 100%|██████████| 13800/13800 [31:23<00:00,  7.33it/s, loss=0.875, lr=0]       \n"
     ]
    }
   ],
   "source": [
    "# 4. Optimized training loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}')\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i, batch in enumerate(progress_bar):\n",
    "        # Move batch to GPU\n",
    "        input_ids = batch['input_ids'].to(\"cuda\")\n",
    "        attention_mask = batch['attention_mask'].to(\"cuda\")\n",
    "        labels = batch['labels'].to(\"cuda\")\n",
    "        \n",
    "        # Mixed precision training\n",
    "        with autocast():\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            loss = outputs.loss / accumulation_steps\n",
    "        \n",
    "        # Scaled backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            # Gradient clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            \n",
    "            # Optimizer and scheduler step\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item() * accumulation_steps\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': loss.item() * accumulation_steps,\n",
    "            'lr': scheduler.get_last_lr()[0]\n",
    "        })\n",
    "        \n",
    "    # Evaluation\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Average loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\potij\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:\n",
      "Average loss: 1.2165\n",
      "Validation F1: 0.0274\n",
      "\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B_BRN       0.00      0.00      0.00        73\n",
      "       B_DES       0.00      0.00      0.00      2620\n",
      "       B_DTM       0.00      0.00      0.00      1979\n",
      "       B_LOC       0.00      0.00      0.00      4611\n",
      "       B_MEA       0.00      0.00      0.00      4042\n",
      "       B_NUM       0.00      0.00      0.00      1642\n",
      "       B_ORG       0.00      0.00      0.00      6390\n",
      "       B_PER       0.00      0.00      0.00      7632\n",
      "       B_TRM       0.00      0.00      0.00       327\n",
      "       B_TTL       0.00      0.00      0.00      2235\n",
      "       E_BRN       0.00      0.00      0.00        13\n",
      "       E_DES       0.00      0.00      0.00       982\n",
      "       E_DTM       0.00      0.00      0.00      1725\n",
      "       E_LOC       0.00      0.00      0.00      4374\n",
      "       E_MEA       0.00      0.00      0.00       866\n",
      "       E_NUM       0.00      0.00      0.00       170\n",
      "       E_ORG       0.00      0.00      0.00      4053\n",
      "       E_PER       0.00      0.00      0.00      4854\n",
      "       E_TRM       0.00      0.00      0.00        30\n",
      "       E_TTL       0.00      0.00      0.00        81\n",
      "       I_BRN       0.00      0.00      0.00         5\n",
      "       I_DES       0.00      0.00      0.00       857\n",
      "       I_DTM       0.00      0.00      0.00      6144\n",
      "       I_LOC       0.00      0.00      0.00      5824\n",
      "       I_MEA       0.00      0.00      0.00      1037\n",
      "       I_NUM       0.00      0.00      0.00       173\n",
      "       I_ORG       0.00      0.00      0.00      4484\n",
      "       I_PER       0.00      0.00      0.00      2162\n",
      "       I_TRM       0.00      0.00      0.00        39\n",
      "       I_TTL       0.00      0.00      0.00       127\n",
      "           O       0.74      1.00      0.85    193930\n",
      "\n",
      "   micro avg       0.74      0.74      0.74    263481\n",
      "   macro avg       0.02      0.03      0.03    263481\n",
      "weighted avg       0.54      0.74      0.62    263481\n",
      " samples avg       0.74      0.74      0.74    263481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_f1, val_report = evaluate(model, eval_loader, id_to_tag)\n",
    "print(f\"\\nEpoch {epoch+1}:\")\n",
    "print(f\"Validation F1: {val_f1:.4f}\")\n",
    "print(\"\\nValidation Report:\")\n",
    "print(val_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>รัฐ</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>B_CLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ถังแตก</td>\n",
       "      <td>VV</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>วิก</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213086</th>\n",
       "      <td>ครหา</td>\n",
       "      <td>VV</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213087</th>\n",
       "      <td>เกี่ยวกับ</td>\n",
       "      <td>VV</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213088</th>\n",
       "      <td>ความ</td>\n",
       "      <td>FX</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213089</th>\n",
       "      <td>ไม่</td>\n",
       "      <td>NG</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213090</th>\n",
       "      <td>ถูกต้อง</td>\n",
       "      <td>VV</td>\n",
       "      <td>O</td>\n",
       "      <td>E_CLS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213091 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word pos tag  class\n",
       "0             รัฐ  NN   O  B_CLS\n",
       "1          ถังแตก  VV   O  I_CLS\n",
       "2             วิก  NN   O  I_CLS\n",
       "3               _  NN   O  I_CLS\n",
       "4               7  NN   O  I_CLS\n",
       "...           ...  ..  ..    ...\n",
       "213086       ครหา  VV   O  I_CLS\n",
       "213087  เกี่ยวกับ  VV   O  I_CLS\n",
       "213088       ความ  FX   O  I_CLS\n",
       "213089        ไม่  NG   O  I_CLS\n",
       "213090    ถูกต้อง  VV   O  E_CLS\n",
       "\n",
       "[213091 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test_data.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions: 257378\n",
      "\n",
      "Sample of updated test data:\n",
      "     word tag\n",
      "0     รัฐ   O\n",
      "1  ถังแตก   O\n",
      "2     วิก   O\n",
      "3       _   O\n",
      "4       7   O\n",
      "5       _   O\n",
      "6      สี   O\n",
      "7     ชวด   O\n",
      "8   โบนัส   O\n",
      "9  ธนาคาร   O\n"
     ]
    }
   ],
   "source": [
    "def predict_tags(model, dataloader, id_to_tag):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # ใช้ enumerate เพื่อติดตามลำดับ batch\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            input_ids = batch['input_ids'].to(\"cuda\")\n",
    "            attention_mask = batch['attention_mask'].to(\"cuda\")\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predictions = torch.argmax(outputs.logits, dim=2).cpu().numpy()\n",
    "            \n",
    "            # Process each sequence in order\n",
    "            for pred, mask in zip(predictions, batch['attention_mask'].numpy()):\n",
    "                valid_indices = mask == 1\n",
    "                pred_sequence = pred[valid_indices]\n",
    "                pred_tags = [id_to_tag[p] for p in pred_sequence]\n",
    "                all_predictions.extend(pred_tags)\n",
    "    \n",
    "    return all_predictions\n",
    "\n",
    "# Get predictions\n",
    "predictions = predict_tags(model, test_loader, id_to_tag)\n",
    "\n",
    "# Update test_df with predictions\n",
    "test_df['tag'] = predictions[:len(test_df)]\n",
    "\n",
    "# Save updated test_df\n",
    "test_df.to_csv('test_data_with_predictions.csv', index=False)\n",
    "\n",
    "print(f\"Total predictions: {len(predictions)}\")\n",
    "print(\"\\nSample of updated test data:\")\n",
    "print(test_df[['word', 'tag']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tag_mapping = {\n",
    "    'O': 0,\n",
    "    'B_ORG': 1, \n",
    "    'B_PER': 2,\n",
    "    'B_LOC': 3,\n",
    "    'B_MEA': 4,\n",
    "    'I_DTM': 5,\n",
    "    'I_ORG': 6,\n",
    "    'E_ORG': 7,\n",
    "    'I_PER': 8,\n",
    "    'B_TTL': 9,\n",
    "    'E_PER': 10,\n",
    "    'B_DES': 11,\n",
    "    'E_LOC': 12,\n",
    "    'B_DTM': 13,\n",
    "    'B_NUM': 14,\n",
    "    'I_MEA': 15,\n",
    "    'E_DTM': 16,\n",
    "    'E_MEA': 17,\n",
    "    'I_LOC': 18,\n",
    "    'I_DES': 19,\n",
    "    'E_DES': 20,\n",
    "    'I_NUM': 21,\n",
    "    'E_NUM': 22,\n",
    "    'B_TRM': 23,\n",
    "    'B_BRN': 24,\n",
    "    'I_TRM': 25,\n",
    "    'E_TRM': 26,\n",
    "    'I_TTL': 27,\n",
    "    'I_BRN': 28,\n",
    "    'E_BRN': 29,\n",
    "    'E_TTL': 30,\n",
    "    'B_NAME': 31\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>class</th>\n",
       "      <th>numeric_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>รัฐ</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>B_CLS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ถังแตก</td>\n",
       "      <td>VV</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>วิก</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213086</th>\n",
       "      <td>ครหา</td>\n",
       "      <td>VV</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213087</th>\n",
       "      <td>เกี่ยวกับ</td>\n",
       "      <td>VV</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213088</th>\n",
       "      <td>ความ</td>\n",
       "      <td>FX</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213089</th>\n",
       "      <td>ไม่</td>\n",
       "      <td>NG</td>\n",
       "      <td>O</td>\n",
       "      <td>I_CLS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213090</th>\n",
       "      <td>ถูกต้อง</td>\n",
       "      <td>VV</td>\n",
       "      <td>O</td>\n",
       "      <td>E_CLS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213091 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word pos tag  class  numeric_tag\n",
       "0             รัฐ  NN   O  B_CLS            0\n",
       "1          ถังแตก  VV   O  I_CLS            0\n",
       "2             วิก  NN   O  I_CLS            0\n",
       "3               _  NN   O  I_CLS            0\n",
       "4               7  NN   O  I_CLS            0\n",
       "...           ...  ..  ..    ...          ...\n",
       "213086       ครหา  VV   O  I_CLS            0\n",
       "213087  เกี่ยวกับ  VV   O  I_CLS            0\n",
       "213088       ความ  FX   O  I_CLS            0\n",
       "213089        ไม่  NG   O  I_CLS            0\n",
       "213090    ถูกต้อง  VV   O  E_CLS            0\n",
       "\n",
       "[213091 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['numeric_tag'] = test_df['tag'].map(lambda x: tag_mapping.get(x, 0))\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03795_0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03795_1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03795_2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03795_3</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03795_4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213086</th>\n",
       "      <td>04276_844</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213087</th>\n",
       "      <td>04276_845</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213088</th>\n",
       "      <td>04276_846</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213089</th>\n",
       "      <td>04276_847</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213090</th>\n",
       "      <td>04276_848</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213091 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   ne\n",
       "0         03795_0  0.0\n",
       "1         03795_1  0.0\n",
       "2         03795_2  1.0\n",
       "3         03795_3  6.0\n",
       "4         03795_4  6.0\n",
       "...           ...  ...\n",
       "213086  04276_844  NaN\n",
       "213087  04276_845  NaN\n",
       "213088  04276_846  NaN\n",
       "213089  04276_847  NaN\n",
       "213090  04276_848  NaN\n",
       "\n",
       "[213091 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pd.read_csv('sample_submission.csv')\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03795_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03795_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03795_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03795_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03795_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213086</th>\n",
       "      <td>04276_844</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213087</th>\n",
       "      <td>04276_845</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213088</th>\n",
       "      <td>04276_846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213089</th>\n",
       "      <td>04276_847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213090</th>\n",
       "      <td>04276_848</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213091 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  ne\n",
       "0         03795_0   0\n",
       "1         03795_1   0\n",
       "2         03795_2   0\n",
       "3         03795_3   0\n",
       "4         03795_4   0\n",
       "...           ...  ..\n",
       "213086  04276_844   0\n",
       "213087  04276_845   0\n",
       "213088  04276_846   0\n",
       "213089  04276_847   0\n",
       "213090  04276_848   0\n",
       "\n",
       "[213091 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['ne'] = test_df['numeric_tag']\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "out.to_csv('sample_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 10905660,
     "sourceId": 91251,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
